# Название семестровой работы

[![CMake](https://github.com/Algorithms-and-Data-Structures-2021/semester-work-suffix-tree-dan/actions/workflows/cmake.yml/badge.svg)](https://github.com/Algorithms-and-Data-Structures-2021/semester-work-suffix-tree-dan/actions/workflows/cmake.yml)

**_Измените status badge сверху для отображения статуса сборки вашего проекта._**

`Actions > CMake > ... > Create status badge`


  В данном проекте реализуется структура данных под названием суффиксное дерево.
**Суффиксное дерево для строки s** – это минимальное по числу вершин дерево, каждое ребро которого помечено непустой подстрокой s таким образом, что каждый суффикс s[i..n-1] может быть прочитан на пути из корня до какого-нибудь листа и, наоборот, каждая строка, прочитанная на пути из корня до какого-нибудь листа, является суффиксом s.
Суффиксное дерево часто используют в задачах со строками: поиск подстроки, наибольшей общей подстроки двух строк, подсчет количества различных подстрок в строке и т.д.
В суффиксном дереве самом по себе есть только одна операция - построение. В данном проекте используются ещё две - проверка наличия подстроки и подсчет количества различных подстрок.
Построение дерева выполняется за T = O(n) и M = O(n), где n - длина строки. Поиск подстроки - T = O(m), где m - длина подстроки, подсчёт количества подстрок - O(n).

## Команда "Odin's bless"


| Фамилия Имя   | Вклад (%) | Прозвище              |
| :---          |   ---:    |  ---:                 |
| Галеев Даниль   | 100       |  Мигель               |

**Девиз команды**

О́ди́н в поле воин!

## Структура проекта

Проект состоит из следующих частей:

- [`src`](src)/[`include`](include) - реализация структуры данных (исходный код и заголовочные файлы);
- [`benchmark`](benchmark) - контрольные тесты производительности структуры данных (операции добавления, удаления,
  поиска и пр.);
- [`examples`](examples) - примеры работы со структурой данных;
- [`dataset`](dataset) - наборы данных для запуска контрольных тестов и их генерация;

## Требования (Prerequisites)

Рекомендуемые требования:

1. С++ компилятор c поддержкой стандарта C++17.
2. Система автоматизации сборки _CMake_ (версия _3.15.x_ и выше).
3. Интерпретатор _Python_ (версия _3.7.x_ и выше).
4. Рекомендуемый объем оперативной памяти - не менее 4 ГБ.
5. Свободное дисковое пространство объемом ~ 3 ГБ (набор данных для контрольных тестов).

## Сборка и запуск



### Пример

#### Сборка проекта

Зайдите на [главную страницу](https://github.com/Algorithms-and-Data-Structures-2021/semester-work-suffix-tree-dan) проекта и нажмите кнопку code, показанную  на рисунке снизу
![clone](https://user-images.githubusercontent.com/70788419/116008429-26ca8100-a61d-11eb-8d58-9a2f5ff2394b.png)
 
 Либо вы можете склонировать себе проект в локальный репозиторий с помощью консольной команды:
```shell
git clone https://github.com/Algorithms-and-Data-Structures-2021/semester-work-template.git
```

Для ручной сборки проекта в терминале введите:

```shell
# переход в папку с проектом
cd C:\Users\username\asd-projects\semester-work-template

# создание папки для файлов сборки (чтобы не засорять папку с проектом) 
mkdir -p build && cd build 

# сборка проекта
cmake .. -DCMAKE_BUILD_TYPE=RelWithDebInfo && cmake --config RelWithDebInfo --build . 
```

Для автоматичекой сборки зайдите в IDE(у меня это CLion) и нажмите на кнопку сборки проекта(в моем случае зеленый молоток)
- [ ] Вставить картинку
#### Генерация тестовых данных
##### Todo
- [ ] Написать про алгоритм генерации тестовых данных


Генерация тестового набора данных в
формате [comma-seperated values (CSV)](https://en.wikipedia.org/wiki/Comma-separated_values):

```shell
# переход в папку генерации набора данных
cd dataset

# запуск Python-скрипта
python generate_csv_bench_dataset.py --samples 1000 <output> [args ...]
```

- `--samples` - количество генерируемых элементов;
- `<output>` - выходной файл и т.д.

Тестовые данные представлены в CSV формате (см.
[`dataset/data/dataset-example.csv`](dataset/data/dataset-example.csv)):

```csv
id, full_name
0, "Ramil Safin"
1, "Bulat Abbyasov"
...
```

**Примечание**. Для удобства запуска контрольных тестов рекомендуется организовывать данные в директориях, например:

```shell
dataset/data/
  tree-creation/
    01/
      100.csv
      ...
      1000000.csv
    02/ ...
    03/ ...
    ...
    10/ ...
  has-substring/
    01/
      100.csv
      ...
      5000000.csv
    ...
    10/ ...
  ...
```

По названию директории `/dataset/data/tree-creation` можно понять, что здесь хранятся наборы данных для контрольных тестов по
**построению дерева**. Названия файлов `100.csv`. `5000000.csv` и т.д. хранят информацию о размере набора данных (т.е. длина строки). 

#### Контрольные тесты (benchmarks)

_Опишите, как запустить контрольные тесты, что они из себя представляют, какие метрики замеряют (время работы,
потребление памяти и пр.)._

Для запуска контрольных тестов необходимо предварительно сгенерировать или скачать готовый набор тестовых данных.

**Примечание**. Во избежание "захламления" репозитория большим объёмом данных рекомендуется указать ссылку на архив с
набором данных, который при необходимости можно скачать по ссылке. Наборы данных должны находиться в папке семестровой
работы на [Google Drive](https://drive.google.com/drive/folders/17-qridbMXFnz3E-6UjOj0WD1H0jWtpz3?usp=sharing).

##### Список контрольных тестов

| Название                  | Описание                                | Метрики         |
| :---                      | ---                                     | :---            |
| `tree_creation_benchmark`    | создание суффиксного дерева             | _время_         |
| `has_substring_benchmark`    | добавление элементов в структуру данных | _время_|
| `count_all_substr_benchmark` | подсчет кол-ва различных подстрок       | _время_             |

##### Примеры запуска

###### Todo
- [ ] Записать алгоритм запуска тестов
```shell
./benchmark <input> <output> --trials 50
```

- `<input>` - входной файл с набором данных в формате CSV;
- `<output>` - выходной файл с результатами контрольного теста;
- `--trials` - количество прогонов на наборе данных и т.д.

Добавление 10000 случайных элементов в структуру данных (повторить операцию 50 раз и вычислить среднее время работы и
потребляемую память):

```
./add_benchmark.exe ../dataset/data/add/10000.csv metrics.txt --trials 50
``` 

где `<input> = ../dataset/data/add/10000.csv` и `<output> = metrics.txt`.

**Примечание**. Файл с метриками не обязателен, можете выводить данные в стандартный поток вывода (т.е. консоль).

## Источники
- [ ] Скопировать список источников из отчета
